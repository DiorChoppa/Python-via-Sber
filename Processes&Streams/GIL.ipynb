{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GIL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMMWXtBOBZie"
      },
      "source": [
        "#GIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki6vuybFBozZ"
      },
      "source": [
        "К сожалению, в Python и его стандартном интерпретаторе CPython только кажется, что потоки выполняются параллельно, на самом деле они выполняются последовательно. Это связано с GIL (Global Interpreter Lock), который ограничивает Python на один запущенный поток в единицу времени.\n",
        "\n",
        "В предыдущем модуле, посвященном сборщику мусора, было описано, что в Python существует система подсчета ссылок на объекты. Проблема, которую решает GIL, связана с возможностью одновременного увеличения или уменьшения ссылок на объекты разными потоками. Может возникнуть ситуация, когда один поток уменьшит число ссылок на объект и Python удалит его, а другой поток будет использовать только что удаленный объект, что приведет к ошибке.\n",
        "\n",
        "В теории такая проблема может быть решена добавлением блокировок к каждому объекту, но, к сожалению, это может привести к проблеме взаимоблокировок — это когда потоки будут находится в режиме ожидания ресурсов, который захватил другой поток, и так бесконечно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh-M4-65BppK"
      },
      "source": [
        "__GIL — это блокировка самого интерпретатора Python. То есть, она является единственной блокировкой в системе и позволяет решить проблему взаимоблокировок, но в свою очередь делает все приложения однопоточными.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skxMQ8kjB9yt"
      },
      "source": [
        "Если разделить все программы на CPU-зависимые (обработка изображений, умножение матриц) и I/O-зависимые (связь по сети, обращение к БД), то можно понять, что использование потоков и GIL не несет ничего критического при I/O-операциях, т.к. время, затраченное Python на переключение потоков, будет компенсировано временем I/O-операций. При этом естественно, что, в не зависимости от количества ядер процессора, любая многопоточная программа на Python не сможет раскрыть потенциал и будет работать даже медленнее однопоточной за счет переключения GIL между потоками.\n",
        "\n",
        "Рассмотрев GIL, следует обратиться к Python-модулю __threading__, который отвечает за создание и работу с потоками."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDEiBi6oBXjA",
        "outputId": "34f3d948-eba5-40e2-cfc3-9fd5ed4e7f42"
      },
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "def thread_function(name):\n",
        "  print(name, \": thread starting\")\n",
        "  time.sleep(2)\n",
        "  print(name, \": after sleep\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Before create Thread\")\n",
        "  x = threading.Thread(target=thread_function, args=(1,))\n",
        "  print(\"Before running Thread\")\n",
        "  x.start()\n",
        "  print(\"Wait Thread finish\")\n",
        "  x.join()\n",
        "  print(\"All done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before create Thread\n",
            "Before running Thread\n",
            "1 : thread starting\n",
            "Wait Thread finish\n",
            "1 : after sleep\n",
            "All done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fvJKDwNEHHK"
      },
      "source": [
        "В данном примере:\n",
        "\n",
        "1. Мы импортируем модуль __threading__.\n",
        "2. Создаем объект класса __Thread__, передавая ему на вход функцию, с которой он начнет работу, и аргументы для этой функции. \n",
        "3. Методом __start()__ можно запустить поток, и, когда он завершит выполнение функции __thread_function()__, он автоматически завершится.\n",
        "\n",
        "Также во время создания объекта класса __Thread__ можно передать параметр __daemon=True__, который позволит создать daemon-поток."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PRtuES1CGQ6"
      },
      "source": [
        "x = threading.Thread(target=thread_function, args=(1,), daemon=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWW-ek8VEiFl"
      },
      "source": [
        "В теории daemon-процесс — это процесс, который работает в фоновом режиме.\n",
        "\n",
        "В Python различают обычные потоки и daemons-потоки. Приложение для остановки будет ждать корректного завершения обычных потоков, daemons-потоки же будут просто убиты. Можно представить, что daemon-поток — это фоновый поток, о завершении которого можно не беспокоиться."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uowqptNvEtc_"
      },
      "source": [
        "__x.join()__ — это указание основному потоку дождаться завершения потока x. Это может быть полезно в случае, когда дочерние потоки делают какую-то работу, а основной поток впоследствии работает с данными, которые подготовили дочерние потоки.\n",
        "\n",
        "Пример, который описан выше, позволяет создавать один поток, а для запуска нескольких можно комбинировать их, помещая в список:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioRhAmOiEs1b",
        "outputId": "d4fc987f-276d-4e2a-e04a-8207b9b16b45"
      },
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "def thread_function(name):\n",
        "  print(name, \": thread starting\\n\")\n",
        "  time.sleep(2)\n",
        "  print(name, \": job is done\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  threads = []\n",
        "  for i in range(3):\n",
        "    print(\"create thread - \", i, \"\\n\")\n",
        "    x = threading.Thread(target=thread_function, args=(i,))\n",
        "    threads.append(x)\n",
        "    x.start()\n",
        "\n",
        "for i, thread in enumerate(threads):\n",
        "  print(\"before join - \", i, \"\\n\")\n",
        "  thread.join()\n",
        "  print(\"after join - \", i, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "create thread -  0 \n",
            "\n",
            "0 : thread starting\n",
            "\n",
            "create thread -  1 \n",
            "\n",
            "1 : thread starting\n",
            "\n",
            "create thread -  2 \n",
            "\n",
            "2before join -  : thread starting\n",
            "\n",
            " 0 \n",
            "\n",
            "0 : job is done\n",
            "\n",
            "after join -  0 \n",
            "\n",
            "before join -  1 \n",
            "\n",
            "1 : job is done\n",
            "\n",
            "after join -  21 \n",
            "\n",
            "before join -  2 \n",
            "\n",
            " : job is done\n",
            "\n",
            "after join -  2 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G19dVhBfGzJE"
      },
      "source": [
        "Можно видеть, что, после старта потоков, главный поток зависает в ожидании потока под номером 0. Но потоки почти в одинаковое время завершают работу, поэтому остальные join() проходят быстро.\n",
        "\n",
        "Помимо создания нескольких потоков и хранения их в списке, в Python есть возможность использовать __ThreadPoolExecutor__, который позволяет создать N потоков более просто."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1do4oEG3FObu"
      },
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def thread_function():\n",
        "  time.sleep(2)\n",
        "  print(\"thread_function Executed {}\".format(threading.current_thread()))\n",
        "\n",
        "def main():\n",
        "  executor = ThreadPoolExecutor(max_workers=3)\n",
        "  task1 = executor.submit(thread_function)\n",
        "  task2 = executor.submit(thread_function)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuDYoPIHNy3w"
      },
      "source": [
        "thread_function Executed <Thread(ThreadPoolExecutor-0_0, started daemon 123145431654400)>\n",
        "thread_function Executed <Thread(ThreadPoolExecutor-0_1, started daemon 123145448443904)>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgwAJtOcO5xp"
      },
      "source": [
        "В этом примере создается ThreadPoolExecutor, с количеством потоков равным 3, и с помощью объекта executor передается функция, которую нужно выполнить. Как видно из вывода, разные потоки выполняют эту функцию."
      ]
    }
  ]
}